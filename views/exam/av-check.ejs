<%- include('../partials/head', { title: 'Audio & Video Verification' }) %>

<div class="min-h-screen bg-gradient-to-br from-blue-600 via-indigo-700 to-purple-800 flex items-center justify-center p-4">
  <div class="bg-white rounded-2xl shadow-2xl w-full max-w-3xl p-8 fade-in">
    <div class="text-center mb-6">
      <h1 class="text-2xl font-bold text-gray-800">Audio & Video Verification</h1>
      <p class="text-gray-500 mt-1"><%= session.exam_title %></p>
    </div>

    <!-- Progress Steps -->
    <div class="flex items-center justify-center mb-8 space-x-2">
      <div class="flex items-center space-x-2">
        <div class="w-8 h-8 bg-green-500 text-white rounded-full flex items-center justify-center text-sm font-bold">&#10003;</div>
        <span class="text-sm text-green-600">System Check</span>
      </div>
      <div class="w-8 h-0.5 bg-green-400"></div>
      <div class="flex items-center space-x-2">
        <div class="w-8 h-8 bg-indigo-600 text-white rounded-full flex items-center justify-center text-sm font-bold">2</div>
        <span class="text-sm font-medium text-indigo-600">A/V Check</span>
      </div>
      <div class="w-8 h-0.5 bg-gray-300"></div>
      <div class="flex items-center space-x-2">
        <div class="w-8 h-8 bg-gray-300 text-gray-500 rounded-full flex items-center justify-center text-sm font-bold">3</div>
        <span class="text-sm text-gray-400">Rules</span>
      </div>
      <div class="w-8 h-0.5 bg-gray-300"></div>
      <div class="flex items-center space-x-2">
        <div class="w-8 h-8 bg-gray-300 text-gray-500 rounded-full flex items-center justify-center text-sm font-bold">4</div>
        <span class="text-sm text-gray-400">Exam</span>
      </div>
    </div>

    <div class="grid md:grid-cols-2 gap-6">
      <!-- Microphone Test Section -->
      <div class="border rounded-xl p-5">
        <h3 class="font-bold text-gray-800 mb-3 flex items-center">
          <svg class="w-5 h-5 mr-2 text-indigo-600" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-14 0m14 0a7 7 0 00-14 0m14 0v1a7 7 0 01-14 0v-1m7 8v4m-4 0h8"/></svg>
          Microphone Test
        </h3>
        <p class="text-sm text-gray-500 mb-3">Please read aloud:</p>
        <div class="bg-indigo-50 border border-indigo-200 rounded-lg p-3 mb-4 text-center">
          <p class="text-indigo-700 font-medium italic">"Hi, I am <strong><%= studentName %></strong>, and I am ready for this test."</p>
        </div>

        <!-- Audio waveform visualization -->
        <div class="bg-gray-100 rounded-lg h-16 mb-3 flex items-center justify-center overflow-hidden" id="waveformContainer">
          <canvas id="waveform" width="300" height="60" class="w-full"></canvas>
        </div>

        <!-- Live speech-to-text display -->
        <div id="speechTextBox" class="bg-gray-50 border border-gray-200 rounded-lg p-3 mb-3 min-h-[48px] hidden">
          <p class="text-xs text-gray-400 mb-1">You said:</p>
          <p id="speechText" class="text-sm text-gray-800 font-medium"></p>
        </div>

        <!-- Speech match result -->
        <div id="speechMatchBox" class="hidden rounded-lg p-3 mb-3 text-sm font-medium text-center"></div>

        <div class="flex space-x-2">
          <button id="startRecordBtn" onclick="startRecording()"
                  class="flex-1 px-4 py-2 bg-red-500 text-white rounded-lg text-sm font-medium hover:bg-red-600 transition cursor-pointer">
            Start Recording
          </button>
          <button id="stopRecordBtn" onclick="stopRecording()" disabled
                  class="flex-1 px-4 py-2 bg-gray-300 text-gray-500 rounded-lg text-sm font-medium cursor-not-allowed">
            Stop Recording
          </button>
        </div>
        <div id="micStatus" class="mt-2 text-sm text-center text-gray-400">Click "Start Recording" to begin</div>
      </div>

      <!-- Webcam & Photo Section -->
      <div class="border rounded-xl p-5">
        <h3 class="font-bold text-gray-800 mb-3 flex items-center">
          <svg class="w-5 h-5 mr-2 text-indigo-600" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 10l4.553-2.276A1 1 0 0121 8.618v6.764a1 1 0 01-1.447.894L15 14M5 18h8a2 2 0 002-2V8a2 2 0 00-2-2H5a2 2 0 00-2 2v8a2 2 0 002 2z"/></svg>
          Webcam & Face Capture
        </h3>

        <div class="bg-yellow-50 border border-yellow-200 rounded-lg p-3 mb-3 text-xs text-yellow-700">
          <p class="font-medium mb-1">Instructions:</p>
          <ul class="list-disc pl-4 space-y-0.5">
            <li>Ensure proper lighting</li>
            <li>Face must be fully visible (forehead, eyes, nose, lips)</li>
            <li>Remove masks / sunglasses</li>
          </ul>
        </div>

        <div class="relative bg-gray-900 rounded-lg overflow-hidden mb-3" style="height: 200px">
          <video id="webcam" autoplay playsinline muted class="w-full h-full object-cover" style="transform: scaleX(-1);"></video>
          <canvas id="photoCanvas" class="hidden"></canvas>
          <canvas id="faceDetectCanvas" class="hidden"></canvas>
          <img id="capturedPhoto" class="hidden w-full h-full object-cover">
          <div id="faceOverlay" class="absolute inset-0 flex items-center justify-center pointer-events-none">
            <!-- Dark mask around the face oval -->
            <svg class="absolute inset-0 w-full h-full" viewBox="0 0 400 200" preserveAspectRatio="none">
              <defs>
                <mask id="faceMask">
                  <rect width="400" height="200" fill="white"/>
                  <ellipse cx="200" cy="95" rx="65" ry="80" fill="black"/>
                </mask>
              </defs>
              <rect width="400" height="200" fill="rgba(0,0,0,0.4)" mask="url(#faceMask)"/>
              <ellipse id="faceOvalStroke" cx="200" cy="95" rx="65" ry="80" fill="none" stroke="white" stroke-width="2" stroke-dasharray="6,4" opacity="0.7"/>
            </svg>
            <p id="faceGuideText" class="absolute bottom-2 text-white/70 text-xs font-medium">Align your face in the oval</p>
          </div>
        </div>

        <div class="flex space-x-2">
          <button id="takePhotoBtn" onclick="takePhoto()" disabled
                  class="flex-1 px-4 py-2 bg-gray-300 text-gray-500 rounded-lg text-sm font-medium cursor-not-allowed">
            Take Photo
          </button>
          <button id="retakePhotoBtn" onclick="retakePhoto()" class="hidden flex-1 px-4 py-2 bg-gray-200 text-gray-700 rounded-lg text-sm font-medium hover:bg-gray-300 transition cursor-pointer">
            Retake
          </button>
        </div>
        <div id="photoStatus" class="mt-2 text-sm text-center text-gray-400">Align your face in the oval to enable capture</div>
      </div>
    </div>

    <!-- Continue Button -->
    <div class="mt-8 text-center">
      <button id="continueBtn" disabled
              class="px-8 py-3 bg-indigo-600 text-white rounded-lg font-semibold hover:bg-indigo-700 transition shadow-lg disabled:bg-gray-300 disabled:cursor-not-allowed cursor-pointer"
              onclick="proceedToRules()">
        Continue to Exam Rules
        <svg class="w-4 h-4 inline ml-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 7l5 5m0 0l-5 5m5-5H6"/></svg>
      </button>
    </div>
  </div>
</div>

<script>
let mediaStream = null;
let mediaRecorder = null;
let audioChunks = [];
let micDone = false, photoDone = false;
let audioContext, analyser, dataArray;
let speechRecognition = null;
let fullTranscript = '';
let faceDetector = null;
let faceDetectionLoop = null;
let faceIsCentered = false;

// Expected text for speech validation
const expectedText = "hi i am <%= studentName.replace(/'/g, "\\'") %> and i am ready for this test";

// Normalize text for comparison: lowercase, remove punctuation, collapse spaces
function normalize(text) {
  return text.toLowerCase().replace(/[^a-z0-9\s]/g, '').replace(/\s+/g, ' ').trim();
}

// Check how well spoken text matches expected text
function checkSpeechMatch(spoken) {
  const spokenNorm = normalize(spoken);
  const expectedNorm = normalize(expectedText);
  const expectedWords = expectedNorm.split(' ');
  const spokenWords = spokenNorm.split(' ');

  // Required words that MUST be present: student name words, "ready", "test"
  const studentName = normalize('<%= studentName %>');
  const nameWords = studentName.split(' ');
  const requiredWords = [...nameWords, 'ready', 'test'];
  const missingRequired = requiredWords.filter(w => !spokenWords.includes(w));
  if (missingRequired.length > 0) {
    return { score: 0, passed: false, missing: missingRequired };
  }

  // Count how many expected words appear in spoken text
  let matched = 0;
  for (const word of expectedWords) {
    if (spokenWords.includes(word)) matched++;
  }
  const score = matched / expectedWords.length;
  return { score, passed: score >= 0.7, missing: [] };
}

// Initialize webcam
async function initWebcam() {
  try {
    mediaStream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode: 'user', width: { ideal: 640 }, height: { ideal: 480 } },
      audio: true
    });
    document.getElementById('webcam').srcObject = mediaStream;

    // Setup audio analyser for waveform
    audioContext = new AudioContext();
    const source = audioContext.createMediaStreamSource(mediaStream);
    analyser = audioContext.createAnalyser();
    analyser.fftSize = 256;
    source.connect(analyser);
    dataArray = new Uint8Array(analyser.frequencyBinCount);

    // Initialize face detection
    initFaceDetection();
  } catch (err) {
    console.error('Media access error:', err);
  }
}
initWebcam();

// ==================== FACE DETECTION ====================

function initFaceDetection() {
  if (window.FaceDetector) {
    faceDetector = new FaceDetector({ fastMode: true, maxDetectedFaces: 5 });
    startFaceDetectionLoop();
  } else {
    // FaceDetector API not available - enable button and allow capture
    faceIsCentered = true;
    const takeBtn = document.getElementById('takePhotoBtn');
    takeBtn.disabled = false;
    takeBtn.className = 'flex-1 px-4 py-2 bg-indigo-600 text-white rounded-lg text-sm font-medium hover:bg-indigo-700 transition cursor-pointer';
    document.getElementById('faceGuideText').textContent = 'Position your face in the oval';
    document.getElementById('photoStatus').textContent = 'Align your face in the oval and take photo';
  }
}

async function detectFaces() {
  if (!faceDetector) return;
  const video = document.getElementById('webcam');
  if (video.readyState < 2) return; // Video not ready

  try {
    const faces = await faceDetector.detect(video);
    const oval = document.getElementById('faceOvalStroke');
    const guideText = document.getElementById('faceGuideText');
    const takeBtn = document.getElementById('takePhotoBtn');

    if (faces.length === 0) {
      // No face detected
      faceIsCentered = false;
      oval.setAttribute('stroke', '#ef4444');
      oval.setAttribute('stroke-dasharray', '6,4');
      guideText.textContent = 'No face detected';
      guideText.className = 'absolute bottom-2 text-red-400 text-xs font-medium';
      takeBtn.disabled = true;
      takeBtn.className = 'flex-1 px-4 py-2 bg-gray-300 text-gray-500 rounded-lg text-sm font-medium cursor-not-allowed';
      return;
    }

    if (faces.length > 1) {
      // Multiple faces
      faceIsCentered = false;
      oval.setAttribute('stroke', '#ef4444');
      oval.setAttribute('stroke-dasharray', '6,4');
      guideText.textContent = 'Only one face allowed';
      guideText.className = 'absolute bottom-2 text-red-400 text-xs font-medium';
      takeBtn.disabled = true;
      takeBtn.className = 'flex-1 px-4 py-2 bg-gray-300 text-gray-500 rounded-lg text-sm font-medium cursor-not-allowed';
      return;
    }

    // Single face - check centering
    const face = faces[0].boundingBox;
    const vw = video.videoWidth;
    const vh = video.videoHeight;

    // Face center position (as fraction of video dimensions)
    const faceCenterX = (face.x + face.width / 2) / vw;
    const faceCenterY = (face.y + face.height / 2) / vh;

    // Face size relative to video
    const faceRelW = face.width / vw;
    const faceRelH = face.height / vh;

    // Centered: face center should be near 0.5, 0.45 (slightly above center)
    const xOk = Math.abs(faceCenterX - 0.5) < 0.15;
    const yOk = Math.abs(faceCenterY - 0.45) < 0.18;
    // Face size: not too small, not too large
    const sizeOk = faceRelW > 0.15 && faceRelW < 0.65 && faceRelH > 0.2 && faceRelH < 0.8;

    if (xOk && yOk && sizeOk) {
      // Face centered
      faceIsCentered = true;
      oval.setAttribute('stroke', '#22c55e');
      oval.setAttribute('stroke-dasharray', 'none');
      guideText.textContent = 'Face aligned - ready to capture';
      guideText.className = 'absolute bottom-2 text-green-400 text-xs font-medium';
      takeBtn.disabled = false;
      takeBtn.className = 'flex-1 px-4 py-2 bg-indigo-600 text-white rounded-lg text-sm font-medium hover:bg-indigo-700 transition cursor-pointer';
    } else {
      // Face detected but not centered
      faceIsCentered = false;
      oval.setAttribute('stroke', '#f59e0b');
      oval.setAttribute('stroke-dasharray', '6,4');
      let hint = 'Move your face ';
      if (!xOk) hint += faceCenterX < 0.5 ? 'right ' : 'left ';
      if (!yOk) hint += faceCenterY < 0.45 ? 'down ' : 'up ';
      if (!sizeOk) hint = faceRelW < 0.15 ? 'Move closer' : 'Move back';
      guideText.textContent = hint.trim();
      guideText.className = 'absolute bottom-2 text-yellow-400 text-xs font-medium';
      takeBtn.disabled = true;
      takeBtn.className = 'flex-1 px-4 py-2 bg-gray-300 text-gray-500 rounded-lg text-sm font-medium cursor-not-allowed';
    }
  } catch (err) {
    // FaceDetector error - gracefully allow capture
    faceIsCentered = true;
    const takeBtn = document.getElementById('takePhotoBtn');
    takeBtn.disabled = false;
    takeBtn.className = 'flex-1 px-4 py-2 bg-indigo-600 text-white rounded-lg text-sm font-medium hover:bg-indigo-700 transition cursor-pointer';
  }
}

function startFaceDetectionLoop() {
  if (faceDetectionLoop) return;
  faceDetectionLoop = setInterval(detectFaces, 500);
}

function stopFaceDetectionLoop() {
  if (faceDetectionLoop) {
    clearInterval(faceDetectionLoop);
    faceDetectionLoop = null;
  }
}

// ==================== SPEECH RECOGNITION ====================

function initSpeechRecognition() {
  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  if (!SpeechRecognition) return null;

  const recognition = new SpeechRecognition();
  recognition.continuous = true;
  recognition.interimResults = true;
  recognition.lang = 'en-IN';

  recognition.onresult = (event) => {
    let finalTranscript = '';
    let interimTranscript = '';
    for (let i = 0; i < event.results.length; i++) {
      const transcript = event.results[i][0].transcript;
      if (event.results[i].isFinal) {
        finalTranscript += transcript;
      } else {
        interimTranscript += transcript;
      }
    }
    fullTranscript = finalTranscript || interimTranscript;

    const speechBox = document.getElementById('speechTextBox');
    const speechText = document.getElementById('speechText');
    speechBox.classList.remove('hidden');
    if (fullTranscript) {
      speechText.innerHTML = `<span class="text-gray-800">${finalTranscript}</span><span class="text-gray-400">${interimTranscript}</span>`;
    }
  };

  recognition.onerror = () => {};
  recognition.onend = () => {};

  return recognition;
}

// ==================== WAVEFORM ====================

function drawWaveform() {
  if (!analyser) return;
  const canvas = document.getElementById('waveform');
  const ctx = canvas.getContext('2d');
  analyser.getByteFrequencyData(dataArray);
  ctx.fillStyle = '#f3f4f6';
  ctx.fillRect(0, 0, canvas.width, canvas.height);
  const barWidth = (canvas.width / dataArray.length) * 2.5;
  let x = 0;
  for (let i = 0; i < dataArray.length; i++) {
    const barHeight = (dataArray[i] / 255) * canvas.height;
    ctx.fillStyle = `rgb(79, 70, 229)`;
    ctx.fillRect(x, canvas.height - barHeight, barWidth, barHeight);
    x += barWidth + 1;
  }
  requestAnimationFrame(drawWaveform);
}
drawWaveform();

// ==================== RECORDING ====================

function startRecording() {
  audioChunks = [];
  fullTranscript = '';
  micDone = false;

  // Reset speech UI
  document.getElementById('speechTextBox').classList.add('hidden');
  document.getElementById('speechText').textContent = '';
  document.getElementById('speechMatchBox').classList.add('hidden');

  mediaRecorder = new MediaRecorder(mediaStream);
  mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
  mediaRecorder.onstop = () => {
    // Validate speech after stopping
    validateSpeech();
  };
  mediaRecorder.start();

  // Start speech recognition
  speechRecognition = initSpeechRecognition();
  if (speechRecognition) {
    try { speechRecognition.start(); } catch (e) {}
  }

  document.getElementById('startRecordBtn').disabled = true;
  document.getElementById('startRecordBtn').className = 'flex-1 px-4 py-2 bg-gray-300 text-gray-500 rounded-lg text-sm font-medium cursor-not-allowed';
  document.getElementById('stopRecordBtn').disabled = false;
  document.getElementById('stopRecordBtn').className = 'flex-1 px-4 py-2 bg-red-500 text-white rounded-lg text-sm font-medium hover:bg-red-600 transition cursor-pointer';
  document.getElementById('micStatus').textContent = 'Recording... Speak the text above clearly';
  document.getElementById('micStatus').className = 'mt-2 text-sm text-center text-red-500 font-medium pulse';
}

function stopRecording() {
  if (mediaRecorder && mediaRecorder.state !== 'inactive') {
    mediaRecorder.stop();
  }
  if (speechRecognition) {
    try { speechRecognition.stop(); } catch (e) {}
  }
  document.getElementById('stopRecordBtn').disabled = true;
  document.getElementById('stopRecordBtn').className = 'flex-1 px-4 py-2 bg-gray-300 text-gray-500 rounded-lg text-sm font-medium cursor-not-allowed';
}

function validateSpeech() {
  const matchBox = document.getElementById('speechMatchBox');
  matchBox.classList.remove('hidden');

  if (!fullTranscript || fullTranscript.trim().length === 0) {
    // No speech detected
    micDone = false;
    matchBox.className = 'rounded-lg p-3 mb-3 text-sm font-medium text-center bg-red-50 border border-red-200 text-red-700';
    matchBox.textContent = 'No speech detected. Please try again.';
    document.getElementById('micStatus').textContent = 'Speech not detected - try again';
    document.getElementById('micStatus').className = 'mt-2 text-sm text-center text-red-500 font-medium';
    enableRetryRecording();
    checkReady();
    return;
  }

  const result = checkSpeechMatch(fullTranscript);
  const matchPercent = Math.round(result.score * 100);

  if (result.passed) {
    // Good match with all required words present
    micDone = true;
    matchBox.className = 'rounded-lg p-3 mb-3 text-sm font-medium text-center bg-green-50 border border-green-200 text-green-700';
    matchBox.innerHTML = `Speech verified (${matchPercent}% match)`;
    document.getElementById('micStatus').textContent = 'Voice verification passed!';
    document.getElementById('micStatus').className = 'mt-2 text-sm text-center text-green-600 font-medium';
  } else {
    // Failed - show what went wrong
    micDone = false;
    matchBox.className = 'rounded-lg p-3 mb-3 text-sm font-medium text-center bg-red-50 border border-red-200 text-red-700';
    if (result.missing.length > 0) {
      matchBox.innerHTML = `Missing required words: <strong>${result.missing.join(', ')}</strong>. Please read the exact text shown above.`;
    } else {
      matchBox.innerHTML = `Speech did not match (${matchPercent}% match). Please read the exact text and try again.`;
    }
    document.getElementById('micStatus').textContent = 'Text did not match - try again';
    document.getElementById('micStatus').className = 'mt-2 text-sm text-center text-red-500 font-medium';
    enableRetryRecording();
  }
  checkReady();
}

function enableRetryRecording() {
  document.getElementById('startRecordBtn').disabled = false;
  document.getElementById('startRecordBtn').className = 'flex-1 px-4 py-2 bg-red-500 text-white rounded-lg text-sm font-medium hover:bg-red-600 transition cursor-pointer';
  document.getElementById('startRecordBtn').textContent = 'Try Again';
}

// ==================== SKIN TONE FACE DETECTION (Fallback) ====================

// Detect skin-tone pixels using YCbCr color space - works across all skin tones
function isSkinPixel(r, g, b) {
  const y  = 0.299 * r + 0.587 * g + 0.114 * b;
  const cb = 128 - 0.169 * r - 0.331 * g + 0.500 * b;
  const cr = 128 + 0.500 * r - 0.419 * g - 0.081 * b;
  return y > 60 && cb > 77 && cb < 127 && cr > 133 && cr < 173;
}

// Analyze the center oval region of the canvas for face presence
function detectFaceInCanvas(canvas) {
  const ctx = canvas.getContext('2d');
  const w = canvas.width;
  const h = canvas.height;
  const imageData = ctx.getImageData(0, 0, w, h);
  const data = imageData.data;

  // Oval region matching the SVG overlay (center of frame)
  const centerX = w / 2;
  const centerY = h * 0.45;
  const radiusX = w * 0.17;
  const radiusY = h * 0.35;

  let skinPixels = 0;
  let totalPixels = 0;
  let rSum = 0, gSum = 0, bSum = 0;

  const step = 3;
  for (let py = Math.max(0, Math.floor(centerY - radiusY)); py < Math.min(h, Math.floor(centerY + radiusY)); py += step) {
    for (let px = Math.max(0, Math.floor(centerX - radiusX)); px < Math.min(w, Math.floor(centerX + radiusX)); px += step) {
      const dx = (px - centerX) / radiusX;
      const dy = (py - centerY) / radiusY;
      if (dx * dx + dy * dy > 1) continue;

      const idx = (py * w + px) * 4;
      const r = data[idx], g = data[idx + 1], b = data[idx + 2];
      totalPixels++;
      rSum += r; gSum += g; bSum += b;
      if (isSkinPixel(r, g, b)) skinPixels++;
    }
  }

  const skinRatio = totalPixels > 0 ? skinPixels / totalPixels : 0;

  // Check color variance (a wall/ceiling is uniform, a face has variation)
  const avgR = rSum / totalPixels, avgG = gSum / totalPixels, avgB = bSum / totalPixels;
  let variance = 0;
  for (let py = Math.max(0, Math.floor(centerY - radiusY)); py < Math.min(h, Math.floor(centerY + radiusY)); py += step * 2) {
    for (let px = Math.max(0, Math.floor(centerX - radiusX)); px < Math.min(w, Math.floor(centerX + radiusX)); px += step * 2) {
      const dx = (px - centerX) / radiusX;
      const dy = (py - centerY) / radiusY;
      if (dx * dx + dy * dy > 1) continue;
      const idx = (py * w + px) * 4;
      variance += Math.pow(data[idx] - avgR, 2) + Math.pow(data[idx+1] - avgG, 2) + Math.pow(data[idx+2] - avgB, 2);
    }
  }
  variance = Math.sqrt(variance / totalPixels);

  const hasFace = skinRatio >= 0.15 && variance > 25;
  return { hasFace, skinRatio: Math.round(skinRatio * 100), variance: Math.round(variance) };
}

// Count separate face regions across the full frame using column-based skin clustering
function countFacesInCanvas(canvas) {
  const ctx = canvas.getContext('2d');
  const w = canvas.width;
  const h = canvas.height;
  if (w === 0 || h === 0) return 0;

  const imageData = ctx.getImageData(0, 0, w, h);
  const data = imageData.data;
  const step = 4;
  const numCols = 40;
  const colSkin = new Array(numCols).fill(0);
  const colTotal = new Array(numCols).fill(0);

  for (let py = 0; py < h; py += step) {
    for (let px = 0; px < w; px += step) {
      const idx = (py * w + px) * 4;
      const colIdx = Math.min(numCols - 1, Math.floor(px / w * numCols));
      colTotal[colIdx]++;
      if (isSkinPixel(data[idx], data[idx + 1], data[idx + 2])) colSkin[colIdx]++;
    }
  }

  const colRatios = colSkin.map((s, i) => colTotal[i] > 0 ? s / colTotal[i] : 0);
  const smoothed = colRatios.map((v, i) => {
    let sum = v, count = 1;
    if (i > 0) { sum += colRatios[i - 1]; count++; }
    if (i < numCols - 1) { sum += colRatios[i + 1]; count++; }
    return sum / count;
  });

  const threshold = 0.12;
  const faceRegions = [];
  let inRegion = false, regionStart = 0, regionPeak = 0;

  for (let i = 0; i < numCols; i++) {
    if (smoothed[i] >= threshold) {
      if (!inRegion) { inRegion = true; regionStart = i; regionPeak = smoothed[i]; }
      else { regionPeak = Math.max(regionPeak, smoothed[i]); }
    } else if (inRegion) {
      if ((i - regionStart) >= 3 && regionPeak >= 0.15) faceRegions.push({ start: regionStart, end: i });
      inRegion = false;
    }
  }
  if (inRegion && (numCols - regionStart) >= 3 && regionPeak >= 0.15) {
    faceRegions.push({ start: regionStart, end: numCols });
  }

  return faceRegions.length;
}

// ==================== PHOTO CAPTURE ====================

async function takePhoto() {
  if (!faceIsCentered && faceDetector) return;

  const video = document.getElementById('webcam');
  const canvas = document.getElementById('photoCanvas');
  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;
  const ctx = canvas.getContext('2d');
  // Mirror the photo to match the mirrored video preview
  ctx.translate(canvas.width, 0);
  ctx.scale(-1, 1);
  ctx.drawImage(video, 0, 0);
  ctx.setTransform(1, 0, 0, 1, 0, 0);

  // Verify face using FaceDetector API if available
  if (faceDetector) {
    try {
      const faces = await faceDetector.detect(canvas);
      if (faces.length !== 1) {
        document.getElementById('photoStatus').textContent = faces.length === 0 ? 'No face detected in photo. Try again.' : 'Multiple faces detected. Only one person allowed.';
        document.getElementById('photoStatus').className = 'mt-2 text-sm text-center text-red-500 font-medium';
        return;
      }
    } catch (e) {}
  }

  // Always run skin tone detection as additional verification
  const faceCheck = detectFaceInCanvas(canvas);
  if (!faceCheck.hasFace) {
    document.getElementById('photoStatus').textContent = 'No face detected. Please position your face clearly in the oval and try again.';
    document.getElementById('photoStatus').className = 'mt-2 text-sm text-center text-red-500 font-medium';
    return;
  }

  // Check for multiple faces using full-frame skin clustering
  const faceCount = countFacesInCanvas(canvas);
  if (faceCount > 1) {
    document.getElementById('photoStatus').textContent = 'Multiple faces detected. Only one person should be in the camera.';
    document.getElementById('photoStatus').className = 'mt-2 text-sm text-center text-red-500 font-medium';
    return;
  }

  stopFaceDetectionLoop();

  const dataUrl = canvas.toDataURL('image/jpeg', 0.8);
  document.getElementById('capturedPhoto').src = dataUrl;
  document.getElementById('capturedPhoto').classList.remove('hidden');
  document.getElementById('webcam').classList.add('hidden');
  document.getElementById('faceOverlay').classList.add('hidden');
  document.getElementById('takePhotoBtn').classList.add('hidden');
  document.getElementById('retakePhotoBtn').classList.remove('hidden');
  document.getElementById('photoStatus').textContent = 'Face captured and verified!';
  document.getElementById('photoStatus').className = 'mt-2 text-sm text-center text-green-600 font-medium';
  photoDone = true;
  checkReady();
}

function retakePhoto() {
  document.getElementById('capturedPhoto').classList.add('hidden');
  document.getElementById('webcam').classList.remove('hidden');
  document.getElementById('faceOverlay').classList.remove('hidden');
  document.getElementById('takePhotoBtn').classList.remove('hidden');
  document.getElementById('retakePhotoBtn').classList.add('hidden');
  document.getElementById('photoStatus').textContent = 'Align your face in the oval to enable capture';
  document.getElementById('photoStatus').className = 'mt-2 text-sm text-center text-gray-400';
  photoDone = false;
  faceIsCentered = false;
  startFaceDetectionLoop();
  checkReady();
}

// ==================== READY CHECK & PROCEED ====================

function checkReady() {
  document.getElementById('continueBtn').disabled = !(micDone && photoDone);
}

async function proceedToRules() {
  const btn = document.getElementById('continueBtn');
  btn.disabled = true;
  btn.textContent = 'Saving...';

  const canvas = document.getElementById('photoCanvas');
  canvas.toBlob(async (blob) => {
    const formData = new FormData();
    formData.append('photo', blob, 'face_capture.jpg');

    const res = await fetch('/exam/save-photo', { method: 'POST', body: formData });
    const data = await res.json();
    if (data.success) {
      stopFaceDetectionLoop();
      if (mediaStream) mediaStream.getTracks().forEach(t => t.stop());
      window.location.href = data.redirect;
    } else {
      btn.disabled = false;
      btn.textContent = 'Continue to Exam Rules';
      alert('Failed to save photo. Please try again.');
    }
  }, 'image/jpeg', 0.8);
}
</script>

<%- include('../partials/footer') %>
